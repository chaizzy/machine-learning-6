{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e27a5589-c8de-4f9e-9bd6-e75c85ee40c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANS 1 :\n",
    "# \"Lasso regularization\" or lasso regression\n",
    "# It is type of regression technique \n",
    "# It is used for feature selection \n",
    "# Lasso regularization, also known as L1 regularization, \n",
    "# is a technique used in machine learning to prevent overfitting and improve the performance and interpretability of a model\n",
    "# Lasso has a tendency to shrink some coefficients to exactly zero. This property makes Lasso regularization useful for feature selection\n",
    "\n",
    "# It differs from ridge regression\n",
    "# lasso uses the absolute values of the coefficients , Ridge uses the squared values of the coefficients .\n",
    "# Ridge regularization tends to shrink the coefficients towards zero but does not set them exactly to zero.\n",
    "\n",
    "# Lasso regularization is more suitable when there is a need for feature selection or when the model's interpretability is crucial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2882f8ad-b31b-4f21-9041-41a585f4dce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANS 2 :\n",
    "# In lasso regression \n",
    "# Lasso has a tendency to shrink some coefficients to exactly zero ,\n",
    "# Which makes the coefficients zero which has very small correlation with respect to  output value\n",
    "# It automatically deletes the features which are not important\n",
    "\n",
    "# main advantages are:\n",
    "# 1.Automatic feature selection: Lasso Regression can automatically select relevant features by driving the coefficients of \n",
    "#  irrelevant or less important features to zero. \n",
    "# 2.Enhanced interpretability: As Lasso Regression tends to set some coefficients to zero, the resulting model is more interpretable.\n",
    "# 3.Handles multicollinearity: Lasso Regression performs well in situations where there is multicollinearity (high correlation) among the \n",
    "#    predictor variables. It tends to select one variable from a group of highly correlated variables while setting the coefficients of the \n",
    "#     others to zero\n",
    "# 4.Flexible regularization strength: Lasso Regression incorporates a regularization parameter (often denoted as lambda or alpha) \n",
    "#    that controls the amount of shrinkage applied to the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baab4103-ff3f-4292-92b6-25b54bd18540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANS 3:\n",
    "# Interpreting the coefficients of a Lasso Regression model is slightly different from  linear regression due to the regularization applied\n",
    "# we can interpret \n",
    "# 1.Non-zero coefficient: If a coefficient is non-zero, it indicates that the corresponding feature has a non-negligible impact on the \n",
    "#    target variable.\n",
    "# 2.Zero coefficient: If a coefficient is exactly zero, it suggests that the corresponding feature has been effectively excluded \n",
    "#   from the model.\n",
    "# 3.Magnitude of coefficients: The magnitude of the non-zero coefficients indicates the strength of the relationship between the \n",
    "#   feature and the target variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72b80e50-28b3-4c80-9f1f-a6d1326e7ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANS 4 :\n",
    "# There are two hypertuning parameters that can effect the model\n",
    "# 1.Regularization parameter (lambda or alpha): This parameter determines the amount of regularization applied to the model. \n",
    "#      --Higher values of the regularization parameter increase the amount of shrinkage applied to the coefficients\n",
    "#      --Conversely, lower values of the regularization parameter reduce the amount of shrinkage, \n",
    "#                    allowing more coefficients to remain non-zero\n",
    "\n",
    "# 2.Elastic Net mixing parameter (alpha): Elastic Net is a variant of Lasso Regression that combines L1 regularization (lasso) and \n",
    "#    L2 regularization (ridge).\n",
    "#    --When alpha is set to 0, Elastic Net becomes equivalent to ridge regression, emphasizing L2 regularization. \n",
    "#    --On the other hand, when alpha is set to 1, Elastic Net becomes equivalent to Lasso Regression, emphasizing L1 regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28a1bd7c-6372-461e-9d92-16eac3f823e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANS 5 :\n",
    "# we can handle non-linear problems through lasso regression\n",
    "# 1.Applying Lasso Regression: Once you have generated the non-linear features, you can apply Lasso Regression to the augmented feature set.\n",
    "# 2.Regularization parameter tuning: When using Lasso Regression for non-linear regression, you still need to tune the \n",
    "#    regularization parameter (lambda or alpha)\n",
    "# 3.Model evaluation: After fitting the Lasso Regression model, you can evaluate its performance using appropriate metrics such as\n",
    "#   mean squared error (MSE), mean absolute error (MAE), or R-squared. \n",
    "#   It's crucial to assess the model's predictive ability on unseen data to ensure it generalizes well beyond the training set.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60fa7d75-d070-4893-9f3d-2ce867c9537a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANS 6 :\n",
    "# # ANS 1 :\n",
    "# \"Lasso regularization\" or lasso regression\n",
    "# It is type of regression technique \n",
    "# It is used for feature selection \n",
    "# Lasso regularization, also known as L1 regularization, \n",
    "# is a technique used in machine learning to prevent overfitting and improve the performance and interpretability of a model\n",
    "# Lasso has a tendency to shrink some coefficients to exactly zero. This property makes Lasso regularization useful for feature selection\n",
    "\n",
    "# It differs from ridge regression\n",
    "# lasso uses the absolute values of the coefficients , Ridge uses the squared values of the coefficients .\n",
    "# Ridge regularization tends to shrink the coefficients towards zero but does not set them exactly to zero.\n",
    "\n",
    "# Lasso regularization is more suitable when there is a need for feature selection or when the model's interpretability is crucial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4931f1e4-6606-4c74-a931-955cd6a1daeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANS 7 :\n",
    "# Yes, Lasso Regression can handle multicollinearity in the input features to some extent. \n",
    "# 1.Coefficient shrinkage: Lasso Regression applies regularization by adding a penalty term to the loss function, \n",
    "#   which includes the absolute values of the regression coefficients. \n",
    "#  This penalty encourages the model to shrink some coefficients towards zero.\n",
    "# 2.Feature selection: Lasso Regression's ability to drive some coefficients to zero provides automatic feature selection. \n",
    "#    When faced with multicollinearity, Lasso Regression can effectively identify and exclude less relevant features from the model\n",
    "# 3.Control over variable selection: By adjusting the regularization parameter (lambda or alpha), \n",
    "#       you have control over the level of shrinkage and sparsity in the model. \n",
    "#      Increasing the regularization parameter increases the amount of shrinkage and encourages more coefficients to be set to zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7115bf40-7f54-43f0-9473-b68c3af75544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANS 8 :\n",
    "# we can choose the optimal value of the regularization parameter (lambda)\n",
    "# 1.Grid search: Grid search is a systematic approach where you define a set of lambda values to evaluate. \n",
    "#       These values are typically chosen in a predefined range, spanning from very small to large values\n",
    "# 2.Regularization path: The regularization path illustrates the behavior of the coefficients as the lambda value changes. \n",
    "#    It shows how the magnitude of the coefficients evolves as the regularization strength increases\n",
    "# 3.Cross-validation: Cross-validation is a widely used technique to estimate the model's performance on unseen data. \n",
    "#   One common approach is k-fold cross-validation, where the dataset is divided into k equal-sized folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590614ba-4381-4e59-8ab3-66f7d31d3705",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
